---
title: "p8105_hw2_cgm2163"
output: html_document
---

# Problem 1

After creating a public GitHub repo and local R project, we should upload the _tidyverse_ library.

```{r}

library(tidyverse)

```

Next, we can upload and clean the **Mr. Trash Wheel** dataset, making sure to create variables with appropriate naming conventions, omitting any non-dumpster specific columns.

```{r}

library(readxl)

# read sheet 1 of the trash wheel collection data set

trash_wheel_data = 
  
  read_excel("./Trash-Wheel-Collection-Totals-8-6-19.xlsx", sheet = 1) %>%
  
  # convert names to lower case snake case
  
  janitor::clean_names() %>%
  
  # create a new variable that rounds the "sports_balls" variable to the nearest integer
  
  mutate(sport_ball = round(sports_balls, digits = 0)) %>%
  
    #select only these variables determined to contain dumpster-specific data, omitting sports_balls, made redundant by the previous step
  
  select(dumpster, month, year, date, weight_tons, volume_cubic_yards,plastic_bottles, polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags, homes_powered, sport_ball) %>%
  
  # omit any rows that do not have complete data for the variable dumpster
  
  drop_na(dumpster)

```

Next, we must clean the **precipitation data** from _2018_.

```{r}

library(readxl)

# read the 2018 precipitation data sheet, skipping the first row and beginning columns are titles

precip_18 = read_excel("./Trash-Wheel-Collection-Totals-8-6-19.xlsx", sheet = ("2018 Precipitation"), skip = 1, col_names = TRUE) %>%
      
      #rename the variable "Total" as "precipitation_inches"
  
      rename(precipitation_inches = Total) %>%
  
      #create a variable called year that is equal to 2018 for all         values
  
      mutate(year = 2018) %>%
  
      # omit any rows which do not have complete data for          precipitation_inches and Month
  
      drop_na(precipitation_inches, Month)

```

Then, we can upload and clean the **precipitation data** from _2019_.

```{r}

# read the 2019 precipitation data sheet, skipping the first row and beginning columns are titles

precip_19 = read_excel("./Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
      sheet = ("2019 Precipitation"), skip = 1, col_names = TRUE) %>%
  
  
    #rename the variable "Total" as "precipitation_inches"
  
    rename(precipitation_inches = Total) %>%
  
    #create a variable called year that is equal to 2019 for all               values
  
    mutate(year = 2019) %>%
  
    #omit any rows that do not have complete data for precipitation or month
  
    drop_na(precipitation_inches, Month) 

```


Now that we have created and cleaned two distinct sheets for our precipitation data, we can join them together to make them more concise.

```{r}
# create a new data set that includes all data points from both the cleaned 2018 and 2019 precipitation data sets.

precip_18_19 =
  full_join(precip_18, precip_19) %>%
  # write over variable Month using month.name function to convert numeric months to month names
  
  mutate(Month = month.name[Month])

```

In _trash_wheel_data_, there are `r count(trash_wheel_data)` observations.

Key variables include dumpster number, month, date, and number of cigarette 
butts, plastic bottles, and other trash collected.


The median number of sports balls in a dumpster in 2019 was `r median(trash_wheel_data$sport_ball[trash_wheel_data$year == 2019]) `.

In _precip_18_19_, there are `r count(precip_18_19)` observations. Key variables 
include month, year, and precipitation inches. The total precipitation in 2018 was `r sum(precip_18_19$precipitation_inches[precip_18_19$year == 2018]) ` inches.


# Problem 2

After downloading the FiveThirtyEight data, we can upload the **pols-month** data set.

```{r}

# create a dataset from pols-month data

pols_month_data = 
  
  read.csv("./pols-month.csv") %>%
  
  # separate mon variable into distinct columns of year, month, and date as integers
  
  separate(mon, c("Year", "Month_old", "day"), sep = "-", convert = TRUE) %>%
  
  # create a new variable based on Month that converts numeric to month names

  mutate(Month = month.abb[Month_old]) %>%
  
  # omit Month variable, made redundant by the last step

  select(-Month_old) %>%

#create a president variable with values gop and dem, omitting prezdem and prezgop variables 

  mutate(president = case_when(prez_gop > 0 ~ "gop", prez_dem > 0 ~ "dem")) %>%
  
# remove unneccessary variables

select(-prez_gop, -prez_dem, -day)

```

Next, we can upload and clean the **snp** dataset.

```{r}

# create a dataset from snp data

library(lubridate)

snp_data = 
  
  read.csv("./snp.csv") %>%

  # read date variable as a type of date instead of character

  mutate(date = mdy(date)) %>%

  # separate date variable into distinct columns of year, month, and date
  
 separate(date, c("Year", "Month_old", "day"), sep = "-", convert = TRUE) %>%
  
   # create a new variable based on Month that converts numeric to month names
  
  mutate(Month = month.abb[Month_old]) %>%

  # omit Month variable, made redundant by the last step
  
  select(-Month_old) %>%
  
  # move day and close columns to the back, moving year and month to lead
  
  select(-day, -close, everything())
  
view(snp_data)

# arrange dates similar to as above year and month should be leading columns

```

Then, we can upload and tidy the **unemployment** dataset.

```{r}

# create data set from unemployment.csv

unemployment_data = 
  
  read.csv("./unemployment.csv") 

# create a new data set where jan:dec become names in a column called month and their values are assigned to a column called unemployment_percent

unemployment_tidy = pivot_longer(unemployment_data, Jan:Dec, names_to = "Month", values_to = "unemployment_percent") %>%

view(unemployment_tidy)

```

Now, we can join the three data sets we have just created.

```{r}
# create a new dataset joining snp_data and pols_month_data

snp_pols =
  full_join(snp_data, pols_month_data)

# create a new dataset joining snp_pols and unemployment_tidy

snp_pols_unemployment =
  full_join(snp_pols, unemployment_tidy)

```

This dataset, _snp_pols_unemployment_, now contains a merged version of the three **FiveThirtyEight** datasets.
Snp_pols contained S&P closing value data for each assoicated date. pols_month_data included observations regarding political affiliation of incumbent politicians. unemployment_data included percentage unemployment by month for each affiliated year. Key variables include month, year, unemployment percent, president, and close. 



# Problem 3

The **NYC Open dataset** on _baby name popularity_ can be assessed by uploading and tidying in Rstudio.

```{r}

# read sheet 1 of the trash wheel collection data set

baby_names_data = 
  
  read.csv("./Popular_Baby_Names.csv")

view(baby_names_data)

# names of a categorical predicor and case structure of string variables has changed over time- needs to be fixed

#some rows seem duplicated, which need to be removed (google "dplyr remove duplicate rows" to get started)

```

Next, we can do some analysis:

```{r}

# produce a reader-friendly table showing the rank in popularity of the name "olivia" as a female baby name over time; needs rows for ethnicities and columns for year

#produce similar table showing most popular name among male children over time

#for male, white non-hispanic children born in 2016, produce a scatter plot showing the number of children with a name (y axis) against the rank in popularity of that name (x axis)


```






